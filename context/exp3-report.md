# 实验三：中文情感分类器 - 实验报告

## 摘要

本报告详细阐述了针对中文汽车评论数据集构建和评估情感分类模型的实验过程与结果。实验旨在比较两种主流方法：基于 TF-IDF 特征的多层感知机 (MLP) 和基于词嵌入的长短期记忆网络 (LSTM)。实验流程遵循标准机器学习实践，从数据加载、全面的探索性数据分析 (EDA) 开始，通过可视化手段（如词频统计、词云图、按情感区分的词频、N-gram 分析）深入理解数据特性。关键预处理步骤包括文本清洗、使用 Jieba 进行中文分词和停用词移除。针对两种模型分别设计了特征工程路径：MLP 使用 TF-IDF 向量，而 LSTM 则构建词汇表、进行序列化和填充。实验对比了两种模型的性能，发现 MLP+TF-IDF 模型虽然简单，但在准确率上较早遭遇瓶颈。LSTM+词嵌入模型展现了更高的性能潜力，能够更好地捕捉文本序列信息，但也表现出对超参数更敏感且更容易过拟合的特性。通过多轮细致的调优（调整学习率、模型复杂度、正则化强度如 Dropout 和权重衰减），有效稳定了 LSTM 的训练过程并抑制了过拟合。最终，评估结果（包括准确率、混淆矩阵、ROC 曲线、Precision-Recall 曲线）表明，经过优化的 LSTM 模型在各项指标上通常优于 MLP 模型。本实验不仅成功构建了两种中文情感分类模型，对比了它们的优劣，也为理解和应用深度学习技术处理中文自然语言处理任务提供了实践经验，并探讨了词嵌入、模型选择和超参数调优在其中的重要性。

## 1. 引言

### 1.1 项目背景与意义

随着互联网信息的爆炸式增长，用户在网络上留下了海量的文本数据，其中蕴含着丰富的情感色彩和观点倾向。情感分析（Sentiment Analysis），又称意见挖掘（Opinion Mining），旨在自动识别、提取、量化和研究文本数据中表达的情感状态和主观信息，已成为自然语言处理 (NLP) 领域的核心研究方向之一，并在商业智能、舆情监控、产品评论分析、社交媒体管理等领域具有广泛的应用价值 [1]。例如，企业可以利用情感分析了解用户对其产品或服务的满意度，及时发现问题并改进；政府机构可以监测社会热点事件的网络情绪，把握公众态度；研究人员可以分析大规模文本数据中的情感演变趋势。

中文情感分析相比英文等语言面临着独特的挑战。中文缺乏明显的词语分隔符，需要进行分词预处理，而分词的准确性直接影响后续分析效果。此外，中文表达方式灵活多样，存在一词多义、网络用语、隐晦表达、反讽等现象，使得情感判断更为复杂 [2]。

近年来，深度学习技术的发展为解决这些挑战提供了强大的工具。传统的基于词典或机器学习（如 SVM、Naive Bayes）的方法往往依赖于手工设计的特征，难以捕捉深层次的语义和上下文信息。深度学习模型，如多层感知机 (MLP)、卷积神经网络 (CNN) 和循环神经网络 (RNN) 及其变种长短期记忆网络 (LSTM) 或门控循环单元 (GRU)，能够自动从数据中学习有效的特征表示 [3]。特别是 LSTM 等 RNN 模型，擅长处理序列数据，能够捕捉文本中的长距离依赖关系，对于理解上下文和语序至关重要的情感分析任务具有天然优势。结合词嵌入 (Word Embeddings) 技术（如 Word2Vec, GloVe 或模型内嵌的 Embedding 层），可以将词语映射到低维稠密向量空间，保留语义信息，进一步提升模型性能。

本项目选择中文汽车评论数据集进行情感分类实验，旨在：1) 实践和比较两种具有代表性的深度学习方法（MLP+TF-IDF vs. LSTM+Embedding）在中文情感分析任务上的应用；2) 深入理解数据预处理、特征表示、模型选择和超参数调优对最终性能的影响；3) 探索深度学习模型解决实际 NLP 问题的能力和挑战。

### 1.2 实验目标

本次实验的具体目标如下：

1.  **数据探索与预处理**: 加载中文汽车评论数据集，进行探索性分析（如文本长度、词频、词云等），并完成文本清洗、分词、去停用词等预处理步骤。
2.  **MLP+TF-IDF 模型实现**: 构建基于 TF-IDF 特征表示的多层感知机模型，进行训练和评估。
3.  **LSTM+Embedding 模型实现**: 构建基于词嵌入和 LSTM 的模型，包括词汇表构建、序列化、填充等步骤，进行训练和评估。
4.  **模型调优**: 针对两个模型训练过程中可能出现的过拟合、欠拟合或训练不稳定等问题，进行超参数调整。
5.  **性能比较与评估**: 使用准确率、混淆矩阵、ROC 曲线、Precision-Recall 曲线等指标，全面比较和评估两个模型的性能。
6.  **结果分析与报告**: 分析实验结果，讨论模型优劣、调优经验和局限性，撰写详细的实验报告。

### 1.3 数据集概述

*   **来源**: `data/exp3` 目录，包含汽车领域的中文评论文本及对应的情感标签。
*   **数据文件**:
    *   `car_sentence.txt`: 每行包含一条评论句子。
    *   `car_label.txt`: 每行包含对应句子的标签 (0 表示负面，1 表示正面)。
*   **样本数量**: 1172 条。
*   **任务类型**: 二元情感分类。
*   **实验代码**: 主要位于 `exp3/sentiment_classifier.py` (MLP) 和 `exp3/sentiment_lstm.py` (LSTM)。数据分析代码位于 `exp3/advanced_analysis.py`。
*   **输出目录**: MLP 相关结果存于 `exp3/output`，LSTM 相关结果存于 `exp3/output_lstm`。

## 2. 数据加载与探索性数据分析 (EDA)

### 2.1 数据加载与标签分布

使用 `pandas` 加载 `car_sentence.txt` 和 `car_label.txt`，合并为一个 DataFrame。首先检查标签分布：

![标签分布](exp3/output/label_distribution.png)

*图 1: 原始数据集情感标签分布图*
**分析**: 该图显示负面评论 (0) 数量略多于正面评论 (1)，但整体分布相对均衡，适合进行二分类任务。

数据集包含 679 条负面评论 (标签 0) 和 493 条正面评论 (标签 1)，类别分布相对均衡。

### 2.2 探索性数据分析 (EDA)

为深入理解数据，执行了 `exp3/advanced_analysis.py` 脚本，生成了以下可视化分析：

*   **文本长度分布**:
    ![原始句子长度分布](exp3/output/original_sentence_length_distribution.png)
    *图 2: 原始句子长度分布（字符数）*
    观察到大部分句子长度集中在较短的范围内。
**分析**: 图表显示评论文本长度主要集中在 0 到 100 个字符之间，呈右偏分布。这提示我们在设置序列填充长度 (如 `MAX_LEN`) 时需要考虑覆盖大部分样本，同时避免过长导致计算浪费。

*   **高频词分析**: (经过清洗、分词、去停用词后)
    ![最高频词语](exp3/output/top_words_frequency.png)
    *图 3: 数据集最高频词语（Top 30）*
    高频词主要围绕汽车相关属性、评价词汇等。
**分析**: 该图展示了去除停用词后频率最高的 30 个词语，如"空间"、"动力"、"外观"、"舒适"等，直观反映了评论内容主要围绕车辆本身的特性和使用感受。

*   **按情感区分的高频词**:
    ![区分情感词频](exp3/output/top_words_by_sentiment.png)
    *图 4: 按情感分类的最高频词语（Top 20）*
    可以看出正面和负面评论常用词汇存在明显差异。
**分析**: 对比正负面评论的高频词，可以发现明显的差异。负面评论中"问题"、"异响"、"不行"等词频率较高，而正面评论中"不错"、"满意"、"喜欢"等词更常见，这验证了使用词语特征进行情感分类的可行性。

*   **高频 Bigrams 分析**:
    ![最高频Bigrams](exp3/output/top_bigrams_frequency.png)
    *图 5: 数据集最高频Bigrams（Top 25）*
    分析常见词组有助于理解上下文。
**分析**: 最高频的二元词组（Bigrams）如"空间大"、"动力足"、"外观漂亮"等，进一步揭示了用户评价的具体方面和常用表达方式。

*   **词云图**:
    ![词云图](exp3/output/wordcloud.png)
    *图 6: 数据集词云图*
    直观展示了数据集的核心词汇。
**分析**: 词云图以视觉化的方式突出了数据集中最核心和最频繁出现的词语，与图 3 的词频统计结果相呼应，再次确认了评论的主要关注点。

## 3. 实验方法

### 3.1 数据预处理

对所有文本数据执行了统一的预处理流程：
1.  **清洗**: 移除所有非中文字符。
2.  **分词**: 使用 `jieba` 库进行中文分词。
3.  **去停用词**: 移除一个预定义的常用中文停用词列表中的词语。

### 3.2 特征工程

根据不同的模型采用不同的特征工程方法：

*   **MLP 模型 (TF-IDF)**:
    *   将预处理后的词语列表转换回以空格分隔的字符串。
    *   使用 `sklearn.feature_extraction.text.TfidfVectorizer` 计算 TF-IDF 特征。
    *   关键参数：`max_features=5000` (限制特征维度)，`ngram_range=(1, 2)` (同时考虑单词和二元词组)。
    *   输出为稀疏矩阵，在送入 PyTorch 模型前转换为稠密 Tensor。

*   **LSTM 模型 (词嵌入)**:
    1.  **构建词汇表**: 仅使用**训练集**数据统计词频，选取最常见的 `VOCAB_SIZE - 2` (例如 9998) 个词语。添加特殊标记 `<PAD>` (索引 0) 和 `<UNK>` (索引 1)。
    2.  **文本序列化**: 将每个评论句子中的词语（已预处理）转换为对应的词汇表索引序列。未登录词 (OOV) 映射为 `<UNK>` 的索引。
    3.  **填充 (Padding)**: 将所有索引序列填充（在末尾添加 `<PAD>` 索引）或截断，使其达到统一的最大长度 `MAX_LEN` (例如 100)。
    4.  输出为 LongTensor，作为 Embedding 层的输入。

### 3.3 模型架构

*   **模型一：MLP (Multi-Layer Perceptron)**
    *   实现于 `exp3/sentiment_classifier.py`。
    *   基于 PyTorch `nn.Module`。
    *   架构：Input (TF-IDF dim) -> Linear(128) -> ReLU -> Dropout(0.3) -> Linear(64) -> ReLU -> Dropout(0.3) -> Linear(1) -> Sigmoid。
    *   (注：隐藏层维度和 Dropout 率为最后一次运行采用的值)
    *   优点：结构简单，训练速度快。
    *   缺点：无法有效利用词语顺序信息，性能可能受限于 TF-IDF 特征。

*   **模型二：LSTM (Long Short-Term Memory)**
    *   实现于 `exp3/sentiment_lstm.py`。
    *   基于 PyTorch `nn.Module`。
    *   架构：
        1.  `nn.Embedding`: 输入词索引序列，输出词嵌入向量 (维度 `EMBEDDING_DIM=100`)，`padding_idx` 设为 0。
        2.  `nn.Dropout`: 对 Embedding 输出进行 Dropout (`DROPOUT_RATE=0.5`)。
        3.  `nn.LSTM`: 使用单层双向 LSTM (`HIDDEN_DIM=128`, `BIDIRECTIONAL=True`) 处理嵌入序列。
        4.  `nn.Dropout`: 对 LSTM 的最终隐藏状态 (拼接双向) 进行 Dropout (`DROPOUT_RATE=0.5`)。
        5.  `nn.Linear`: 将处理后的隐藏状态映射到单个输出单元。
        6.  `nn.Sigmoid`: 输出最终的概率。
    *   (注：参数为最后一次运行采用的值)
    *   优点：能捕捉文本的序列依赖关系和上下文信息。
    *   缺点：模型更复杂，参数量更大，训练时间更长，更容易过拟合。

### 3.4 实验设置与评估指标

*   **框架与库**: PyTorch, Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn, Jieba。
*   **数据划分**: 使用 `train_test_split` 将数据划分为 80% 训练集和 20% 验证集，采用分层抽样 (`stratify=y`) 保证类别比例。
*   **优化器**: 均使用 Adam 优化器。
*   **损失函数**: 均使用 BCELoss (二元交叉熵损失)，适用于 Sigmoid 输出的二分类任务。
*   **评估指标**:
    *   准确率 (Accuracy)
    *   精确率 (Precision)
    *   召回率 (Recall)
    *   F1 分数 (F1-Score)
    *   混淆矩阵 (Confusion Matrix)
    *   ROC 曲线 (Receiver Operating Characteristic Curve) 和 AUC 值 (Area Under Curve)
    *   Precision-Recall 曲线

### 3.5 原理介绍

本实验采用了两种不同的技术路线进行情感分类，涉及的关键技术原理如下：

*   **TF-IDF (Term Frequency-Inverse Document Frequency)**:
    *   **原理**: TF-IDF 是一种统计方法，用以评估一个词语对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加（TF - 词频），但同时会随着它在语料库中出现的频率成反比下降（IDF - 逆文档频率）。IDF 的主要思想是：如果包含词条 t 的文档越少，IDF 值越大，则说明词条 t 具有很好的类别区分能力。
    *   **应用**: 在本实验中，TF-IDF 用于将文本转换为数值向量，作为 MLP 模型的输入特征。它简单有效，但忽略了词语的顺序和深层语义信息。

*   **MLP (Multi-Layer Perceptron)**:
    *   **原理**: MLP 是一种前馈人工神经网络模型，它将输入的向量映射到一组输出向量。MLP 至少由三层节点组成：输入层、一个或多个隐藏层和输出层。除了输入节点，每个节点都是一个带有非线性激活函数（如 ReLU）的神经元。MLP 利用反向传播算法进行训练，通过调整层与层之间的连接权重来学习输入和输出之间的复杂非线性关系。
    *   **应用**: 在本实验中，MLP 用于接收 TF-IDF 特征，并学习如何根据这些特征进行情感分类。

*   **词嵌入 (Word Embeddings)**:
    *   **原理**: 词嵌入是将词语或短语从词汇表中映射到低维实数向量的技术。其核心思想是，语义上相似的词语在向量空间中的距离也应该相近。与 TF-IDF 等稀疏表示不同，词嵌入是稠密的，能更好地捕捉词语之间的语义和句法关系。常见的词嵌入方法有 Word2Vec, GloVe 等，也可以在模型训练过程中学习得到（如本实验中的 `nn.Embedding` 层）。
    *   **应用**: 在 LSTM 模型中，词嵌入层将输入的词语索引序列转换为稠密向量序列，为后续的 LSTM 层提供更丰富的语义信息输入。

*   **LSTM (Long Short-Term Memory)**:
    *   **原理**: LSTM 是一种特殊的循环神经网络 (RNN)，旨在解决标准 RNN 中的长期依赖问题（梯度消失/爆炸）。LSTM 通过引入"门控机制"（输入门、遗忘门、输出门）和一个"细胞状态"来实现这一点。这些门可以控制信息的流动：哪些信息需要被遗忘，哪些新信息需要被添加到细胞状态中，以及基于当前输入和细胞状态输出什么。这使得 LSTM 能够有效地学习和记住文本序列中的长期模式和依赖关系。双向 LSTM (Bi-LSTM) 则能同时考虑过去和未来的上下文信息。
    *   **应用**: 在本实验中，LSTM 用于处理词嵌入序列，捕捉文本中的上下文和语序信息，以进行更精准的情感判断。

## 4. 实验结果与分析

(注：以下结果基于报告撰写前最后一次运行脚本的输出，具体数值可能因随机性和调参历史略有不同。)

### 4.1 MLP 模型性能

*   **训练过程**:
    ![MLP 训练历史](exp3/output/training_history.png)
    *图 7: MLP 模型训练与验证准确率/损失曲线 (最后一次运行)*
    损失曲线显示稳定收敛，但准确率曲线在约第 5 个 epoch 后进入平台期，训练准确率 (~75.6%) 与验证准确率 (~75.8%) 之间存在微小但稳定的差距，未能进一步提升。这表明模型或特征已达瓶颈。
**分析**: 训练损失和验证损失均下降并趋于稳定，表明模型收敛。但训练准确率和验证准确率在早期提升后迅速进入平台期，且两者差距很小，说明模型没有明显过拟合，但也未能从数据中学到更多信息，性能达到了基于 TF-IDF 特征的 MLP 模型的上限。

*   **最终评估**: (参考图 8, 9, 10 及控制台输出)
    ![MLP 混淆矩阵](exp3/output/confusion_matrix.png)
    *图 8: MLP 模型混淆矩阵 (最后一次运行)*
**分析**: 混淆矩阵展示了模型在验证集上的具体分类结果。对角线上的数值（如左上角的负类正确预测数和右下角的正类正确预测数）表示预测正确的样本数，非对角线表示预测错误的样本数。可以看出模型在两个类别上的表现相对均衡，但存在一定数量的误分类。

    ![MLP ROC曲线](exp3/output/roc_curve.png)
    *图 9: MLP 模型 ROC 曲线 (最后一次运行)*
**分析**: ROC 曲线描绘了不同分类阈值下真阳性率 (TPR) 与假阳性率 (FPR) 的关系。曲线越靠近左上角，性能越好。AUC (曲线下面积) 值为 0.82，表示模型具有一定的区分正负样本的能力，显著优于随机猜测（AUC=0.5 的对角线）。

    ![MLP PR曲线](exp3/output/precision_recall_curve.png)
    *图 10: MLP 模型 Precision-Recall 曲线 (最后一次运行)*
**分析**: Precision-Recall 曲线展示了精确率 (Precision) 和召回率 (Recall) 之间的权衡关系。该曲线同样越靠近右上角性能越好。此图可用于评估模型在关注正类别（例如识别所有正面评论）时的表现。

    MLP 模型最终在验证集上获得了约 76% 的准确率和约 0.82 的 AUC 值。性能尚可，但受限于准确率平台期。

### 4.2 LSTM 模型性能

*   **训练过程**:
    ![LSTM 训练历史](exp3/output_lstm/training_history_lstm.png)
    *图 11: LSTM 模型训练与验证准确率/损失曲线 (最后一次运行)*
    经过调优（降低学习率 `2e-4`，增加 Dropout `0.5` 和权重衰减 `1e-4`）后，训练过程变得稳定。训练准确率持续上升至约 86%，验证准确率也上升至约 80% 左右，显著优于 MLP。但在训练后期，验证损失有轻微抬头趋势，表明仍存在轻微过拟合。
**分析**: 与 MLP 相比，LSTM 模型的训练准确率和验证准确率都达到了更高的水平。虽然训练后期验证损失略有上升，显示出轻微过拟合的迹象，但整体性能显著优于 MLP。这表明 LSTM 更好地利用了文本的序列信息。训练曲线也显示出通过调优（如降低学习率、增加正则化）可以有效控制 LSTM 的训练过程。

*   **最终评估**: (参考图 12, 13, 14 及控制台输出)
    ![LSTM 混淆矩阵](exp3/output_lstm/confusion_matrix_lstm.png)
    *图 12: LSTM 模型混淆矩阵 (最后一次运行)*
**分析**: 对比图 8，LSTM 模型在混淆矩阵对角线上的数值（正确预测数）更高，非对角线上的数值（错误预测数）更低，表明其在正负类别上的分类准确性均优于 MLP 模型。

    ![LSTM ROC曲线](exp3/output_lstm/roc_curve_lstm.png)
    *图 13: LSTM 模型 ROC 曲线 (最后一次运行)*
**分析**: LSTM 的 ROC 曲线更靠近左上角，其 AUC 值为 0.88，高于 MLP 的 0.82。这进一步证明 LSTM 模型具有更强的区分正负样本的能力。

    ![LSTM PR曲线](exp3/output_lstm/precision_recall_curve_lstm.png)
    *图 14: LSTM 模型 Precision-Recall 曲线 (最后一次运行)*
**分析**: LSTM 的 Precision-Recall 曲线整体位于 MLP 曲线的上方，表明在相同的召回率下，LSTM 通常能达到更高的精确率，综合性能更优。

    LSTM 模型最终在验证集上获得了约 80% 的准确率和约 0.88 的 AUC 值。各项指标均优于 MLP 模型，证明了 LSTM 结合词嵌入在捕捉文本序列信息方面的优势。

### 4.3 调优过程总结

*   **MLP**: 主要面临准确率平台期问题。尝试了调整学习率、批次大小、模型复杂度、正则化强度。虽然稳定了训练，但未能突破准确率瓶颈，促使转向 LSTM 模型。
*   **LSTM**: 初期使用较高学习率 (`1e-3`) 时出现严重过拟合和训练不稳定（验证损失飙升）。通过显著降低学习率 (`2e-4`) 并加强正则化（增加 Dropout 和 Weight Decay）成功稳定了训练过程，抑制了大部分过拟合，并获得了比 MLP 更好的性能。

## 5. 讨论

*   **模型与特征选择**: 实验清晰地展示了特征表示和模型架构对 NLP 任务性能的关键影响。TF-IDF 作为一种基于词频的统计方法，丢失了语序信息，限制了 MLP 模型的上限。词嵌入保留了更多语义信息，而 LSTM 则能有效处理序列依赖，两者结合通常能带来更好的性能，但也对计算资源和调优技巧提出了更高要求。
*   **过拟合与正则化**: LSTM 模型由于其复杂性更容易过拟合。实验证明，降低学习率、使用 Dropout 和权重衰减是有效的正则化手段。找到合适的平衡点（既能有效学习，又不过度拟合）是调优过程的核心。
*   **实验局限性**:
    *   **词嵌入**: 使用的是随机初始化的 Embedding 层。加载预训练的中文词向量（如腾讯、百度的开源向量）或使用更强大的预训练语言模型（如 BERT）的 Embedding 可能会大幅提升性能。
    *   **模型结构**: 仅使用了单层双向 LSTM。可以尝试更深层的 LSTM、GRU 或者结合 CNN 的混合模型。
    *   **数据量**: 1172 条样本对于深度学习模型来说偏少，可能限制了模型的泛化能力。
    *   **超参数优化**: 手动调优效率较低且可能错过最优解。自动化超参数搜索工具（如 Optuna, Hyperopt）或更系统的搜索策略（网格/随机搜索）会更有优势。

## 6. 结论

本实验通过构建、训练、评估和调优 MLP+TF-IDF 和 LSTM+词嵌入两种模型，对中文汽车评论数据集进行了情感分类。主要结论如下：

1.  基于 TF-IDF 的 MLP 模型可以作为快速实现的基线，但在处理需要理解语序和深层语义的任务时性能受限。
2.  基于词嵌入的 LSTM 模型能够更好地捕捉文本的序列特征，展现出更高的性能潜力，是处理此类 NLP 任务更优的选择。
3.  深度学习模型（尤其是 LSTM）对超参数敏感且易过拟合，细致的调优（特别是学习率和正则化策略）对于获得稳定且高性能的模型至关重要。
4.  探索性数据分析为理解数据和指导模型选择提供了有价值的见解。

未来的工作可以探索使用预训练词嵌入/语言模型、更复杂的网络结构以及更系统化的超参数优化方法，以期进一步提升模型性能。

## 7. 参考文献

[1] Liu, B. (2012). Sentiment analysis and opinion mining. *Synthesis lectures on human language technologies*, 5(1), 1-167.
[2] Zhang, L., Wang, S., & Liu, B. (2018). Deep learning for sentiment analysis: A survey. *Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery*, 8(4), e1253.
[3] Young, T., Hazarika, D., Poria, S., & Cambria, E. (2018). Recent trends in deep learning based natural language processing. *IEEE Computational Intelligence Magazine*, 13(3), 55-75. 